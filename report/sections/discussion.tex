% Vurdering 1/5
%Du skal her drøfte resultatene dine og sette dem inn i en sammenheng. Å drøfte vil si å:

%sette ulike synspunkter, momenter, argumenter, faktorer og årsaker opp mot hverandre
%vurdere og sette dem opp mot hverandre. Finnes det flere ulike tolkninger av resultatene?
%Du må i kapitlet svare på:

%hvordan svarer resultatene dine på forskningsspørsmålene dine?
%hva betyr resultatene?
%Et lurt tips er å gjenta forskningsspørsmålene, slik at leseren blir minnet på hva de er.

%Du skal òg se tilbake på studien og vurdere hvor gyldig og pålitelig den har vært.

%Hva kunne blitt gjort annerledes?
%Hva er sterke og svake sider?
%Her kan du for eksempel kritisere metodene som du har brukt, og forklare hva du kunne gjort annerledes.

\section{Diskusjon}
\label{part:discussion}
Datasettet burde bestå av data uten bias. Modellene som er trent kan effektivt se forskjell på torsk og sei som finnes i bildene, men ettersom bildene ble tatt på så forskjellige måter, der sei dataen var i gråtoner og torsk var i farger, så vil modellen muligens se etter fisk av gråtoner, ikke sei, når den gjør inferens. Datasettet bestod av 208 bilder av torsk, med til sammen 4582 instanser av torsk i bildene. Det var 604 bilder av sei med 5525 instanser av fisken i bildene. Det er litt flere instanser av sei enn av torsk. Det kan også øke bias i modellen i noe grad.

Det som er lettere for mennesker å forstå er også lettere for maskiner å forstå. Data is king innenfor maskinsyn, å ha gode bilder er et must for å få gode resultater. Det betyr ikke at et bilde av gråtoner, eller av lav oppløsning er dårlige. Det er faktisk mange fordeler med gråtoner og lav oppløsning. De kan prosesseres raskt, og av og til så blir de viktigste egenskapene mer synlige.

RetinaNet-modellen hadde overraskende lav Average Precision og Average Recall og kan forbedres ved å trenes på nytt, for eksempel med et større antall iterasjoner eller ved å justere learning-rate. 

YOLOv4-modellen hadde ganske gode resultater. Learning loss burde egentlig være mellom 3,0 og 0,05, men endte opp på litt over 5,0. Modellen kan forbedres ved å trene modellen over flere iterasjoner eller ved å justere learning rate.

Fish4Knowledge-, LifeCLEF- og SeaCLEF-datasettene kan legges til modellen, da vil den kjenne igjen flere fiskearter.

OpenCV-programmet og YOLOv4-modellen kan testes videre, og trenes opp på data uten bias. Modellene bør testes på en videostrøm som inneholder både torsk og sei, og testes på data fra under oppdrettsanlegg for å se om den virker til den påtenkte arbeidsoppgaven den er laget for. Etter videre testing og eventuell trening på ny data så kan modellene og OpenCV programmet bli brukt til å hjelpe oppdrettsnæringen til å kontroll på overfôring, samt å gi en oversikt over mengden torsk og sei som trekker til oppdrettsanleggene.

%The most important outcome of this research is the classification accuracy achieved. With the other species class included, the accu- racy of the classification is 89.0 \%, which is competitive with or exceeds other recently reported results on fish species identifica- tion tasks (Hsiao et al., 2014; Huang et al., 2015; Salman et al., 2016). If the other species class is excluded, the classification accu- racy within the 16 species classes is 94.3 \%, which is competitive with the identification rates of human experts for similar tasks (Culverhouse et al., 2003).